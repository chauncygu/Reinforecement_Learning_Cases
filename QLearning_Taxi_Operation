import numpy as np
import gym
import random

print("The game will be started!")
env = gym.make("Taxi-v3")
env.render()

action_size = env.action_space.n  # 获取动作维度（一个状态下有几种动作选择）
print("Action size ", action_size)
state_size = env.observation_space.n  # 获取状态维度（一共多少种状态）
print("State size ", state_size)
qtable = np.zeros((state_size, action_size))  # 初始化 Q 表
print(qtable)

total_episodes = 50000  # 一共玩多少局游戏
total_test_episodes = 100  # 测试中一共走几步
max_steps = 99  # 每一局游戏最多走几步
learning_rate = 0.7  # 学习率
gamma = 0.618  # 未来奖励折扣率# 探索相关参数
epsilon = 0.4  # 探索概率
max_epsilon = 1.0  # 一开始的探索概率
min_epsilon = 0.01  # 最低的探索概率
decay_rate = 0.01  # 探索概率的指数衰减概率

# 重置环境
state = env.reset()
step = 0
done = False
for step in range(max_steps):
    exp_exp_tradeoff = random.uniform(0, 1)
    if exp_exp_tradeoff > epsilon:
        action = np.argmax(qtable[state, :])

    else:
        action = env.action_space.sample()
    new_state, reward, done, info = env.step(action)
    qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma *np.max(qtable[new_state, :]) - qtable[state, action])
    state = new_state
    if done == True:
        break
    #epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-(decay_rate))
    epsilon = epsilon-0.01


env.reset()
rewards = []
for episode in range(total_test_episodes):
    state = env.reset()
    step = 0
    done = False
    total_rewards = 0
    print("****************************************************")
    print("EPISODE ", episode)
    for step in range(max_steps):
        env.render()
        action = np.argmax(qtable[state, :])
        new_state, reward, done, info = env.step(action)
        total_rewards += reward
        print("Score1", total_rewards)
        if done:
            rewards.append(total_rewards)
            print("Score", total_rewards)
            break
        state = new_state
env.close()
print ("Score over time: " ,(sum(rewards)/total_test_episodes))

